"""
Vizra Configuration File Example

Copy this file to 'vizra_config.py' in your project root and customize as needed.
You can add any configuration values you want - this is just a Python dictionary!
"""

import os

settings = {
    # LLM Configuration
    'llm': {
        'model': os.getenv('VIZRA_MODEL', 'gpt-4o'),
        'temperature': 0.7,
        'max_tokens': 2000,
        'timeout': 30,
        # Optional: Set a custom API base URL for proxies or custom endpoints
        # 'api_base': 'https://custom-proxy.com/v1',
    },
    
    # Agent Configuration
    'agent': {
        'max_tool_iterations': 3,
        'default_model': 'gpt-4o',
        'instructions_dir': './prompts',
    },
    
    # Training Configuration
    'training': {
        'algorithm': 'ppo',
        'batch_size': 32,
        'learning_rate': 1e-4,
        'n_iterations': 100,
        'results_dir': './training/results',
        'gradient_accumulation_steps': 1,
        'gradient_checkpointing': True,
    },
    
    # Evaluation Configuration
    'evaluation': {
        'batch_size': 16,
        'results_dir': './evaluation_results',
        'save_responses': True,
    },
    
    # Note: API keys should be set as environment variables:
    # - OPENAI_API_KEY for OpenAI models
    # - ANTHROPIC_API_KEY for Claude models
    # - AZURE_API_KEY, AZURE_API_BASE, AZURE_API_VERSION for Azure
    # - And other provider-specific environment variables
    # LiteLLM will automatically read these environment variables
    
    # Provider-specific settings
    'providers': {
        'verifiers': {
            'inference_url': os.getenv('VLLM_SERVER_URL', 'http://localhost:8000/v1'),
            'model_path': './models',
        },
        # Add your own provider configurations
    },
    
    # File paths
    'paths': {
        'data': './data',
        'outputs': './outputs',
        'logs': './logs',
    },
    
    # Feature flags
    'features': {
        'verbose_logging': False,
        'debug_mode': os.getenv('DEBUG', 'false').lower() == 'true',
        'experimental': {
            'new_algorithm': False,
        },
    },
    
}

# Example: Environment-specific configuration
# if os.getenv('ENVIRONMENT') == 'production':
#     settings['llm']['temperature'] = 0.3  # More deterministic in production
#     settings['features']['debug_mode'] = False

# Example: Custom configuration for your own use
# settings['my_custom_config'] = {
#     'special_value': 42,
#     'api_endpoint': 'https://my-api.example.com',
# }